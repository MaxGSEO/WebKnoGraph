{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx5YXxqgrbEH"
      },
      "outputs": [],
      "source": [
        "!pip install trafilatura sentence-transformers torch pandas pyarrow duckdb scipy -q\n",
        "!pip install fireducks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "QO9Ir6L3r1Dd",
        "outputId": "d34ee01f-0dc2-415a-f32d-d68adf878ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mblock_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2969880294>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not launch Gradio demo in this environment.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[0m\n\u001b[1;32m   2979\u001b[0m             )\n\u001b[1;32m   2980\u001b[0m         ):\n\u001b[0;32m-> 2981\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTupleNoPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mblock_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keyboard interruption in main thread... closing server.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3079\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3080\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtunnel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCURRENT_TUNNELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                 \u001b[0mtunnel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#\n",
        "# --- Step 2: Import Libraries ---\n",
        "#\n",
        "import gradio as gr\n",
        "import duckdb\n",
        "# import pandas as pd\n",
        "import fireducks.pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import logging\n",
        "import time\n",
        "import trafilatura\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "# Suppress a common warning from the sentence-transformers library\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\")\n",
        "\n",
        "\n",
        "#\n",
        "# --- Step 3: Configuration & Core Interfaces ---\n",
        "#\n",
        "\n",
        "@dataclass\n",
        "class EmbeddingConfig:\n",
        "    \"\"\"Holds all configuration settings for the pipeline.\"\"\"\n",
        "    input_path: str = \"/content/drive/My Drive/master_july_2025/data/crawled_data_parquet/\"\n",
        "    output_path: str = \"/content/drive/My Drive/master_july_2025/data/url_embeddings/\"\n",
        "    model_name: str = 'all-MiniLM-L6-v2' # should be changed to other/multilingual content if the content is not in English\n",
        "    batch_size: int = 10\n",
        "\n",
        "class ILogger(ABC):\n",
        "    \"\"\"Interface for logging messages.\"\"\"\n",
        "    @abstractmethod\n",
        "    def info(self, message: str): pass\n",
        "    @abstractmethod\n",
        "    def error(self, message: str): pass\n",
        "    @abstractmethod\n",
        "    def exception(self, message: str): pass\n",
        "\n",
        "class ConsoleAndGradioLogger(ILogger):\n",
        "    \"\"\"Logs messages to the console and a Gradio UI component.\"\"\"\n",
        "    def __init__(self, log_output_stream: io.StringIO, level=logging.INFO):\n",
        "        self._logger = logging.getLogger(\"EmbeddingLogger\")\n",
        "        self._logger.setLevel(level)\n",
        "        if self._logger.hasHandlers():\n",
        "            self._logger.handlers.clear()\n",
        "\n",
        "        # Console handler\n",
        "        console_handler = logging.StreamHandler()\n",
        "        console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
        "        self._logger.addHandler(console_handler)\n",
        "\n",
        "        # Gradio handler\n",
        "        gradio_handler = logging.StreamHandler(log_output_stream)\n",
        "        gradio_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
        "        self._logger.addHandler(gradio_handler)\n",
        "\n",
        "    def info(self, message: str): self._logger.info(message)\n",
        "    def error(self, message: str): self._logger.error(message)\n",
        "    def exception(self, message: str): self._logger.exception(message)\n",
        "\n",
        "#\n",
        "# --- Step 4: Component Classes (Single Responsibility Principle) ---\n",
        "#\n",
        "\n",
        "class EmbeddingStateManager:\n",
        "    \"\"\"Manages the state of the embedding process, enabling resumes.\"\"\"\n",
        "    def __init__(self, output_path: str, logger: ILogger):\n",
        "        self.output_path = output_path\n",
        "        self.logger = logger\n",
        "\n",
        "    def get_processed_urls(self) -> set:\n",
        "        \"\"\"Scans the output directory to find URLs that have already been embedded.\"\"\"\n",
        "        processed_urls = set()\n",
        "        if not os.path.exists(self.output_path):\n",
        "            os.makedirs(self.output_path)\n",
        "            self.logger.info(\"Output directory created.\")\n",
        "            return processed_urls\n",
        "\n",
        "        try:\n",
        "            output_glob_path = os.path.join(self.output_path, '*.parquet')\n",
        "            # Use DuckDB for efficient scanning of existing results\n",
        "            processed_df = duckdb.query(f\"SELECT DISTINCT URL FROM read_parquet('{output_glob_path}')\").to_df()\n",
        "            processed_urls = set(processed_df['URL'])\n",
        "            if processed_urls:\n",
        "                self.logger.info(f\"Found {len(processed_urls)} URLs that have already been processed. They will be skipped.\")\n",
        "        except Exception:\n",
        "            self.logger.info(\"No previously processed embeddings found. Starting fresh.\")\n",
        "        return processed_urls\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Responsible for loading unprocessed data in batches.\"\"\"\n",
        "    def __init__(self, input_path: str, logger: ILogger):\n",
        "        self.input_path = input_path\n",
        "        self.logger = logger\n",
        "        self.con = duckdb.connect()\n",
        "\n",
        "    def stream_unprocessed_data(self, processed_urls: set, batch_size: int):\n",
        "        \"\"\"A generator that yields batches of new data to be processed.\"\"\"\n",
        "        input_glob_path = os.path.join(self.input_path, '**', '*.parquet')\n",
        "        base_query = f\"SELECT URL, Content FROM read_parquet('{input_glob_path}') WHERE Status_Code >= 200 AND Status_Code < 300 AND Content IS NOT NULL AND Content != ''\"\n",
        "\n",
        "        if processed_urls:\n",
        "            processed_urls_df = pd.DataFrame(list(processed_urls), columns=['URL'])\n",
        "\n",
        "            # --- THIS IS THE FIX ---\n",
        "            # We replace the non-standard \"LEFT ANTI JOIN\" with a standard\n",
        "            # \"LEFT JOIN\" and a \"WHERE ... IS NULL\" check. This achieves the same goal.\n",
        "            final_query = f\"\"\"\n",
        "                SELECT t1.URL, t1.Content\n",
        "                FROM ({base_query}) AS t1\n",
        "                LEFT JOIN processed_urls_df AS t2 ON t1.URL = t2.URL\n",
        "                WHERE t2.URL IS NULL\n",
        "            \"\"\"\n",
        "            # --- END OF FIX ---\n",
        "        else:\n",
        "            final_query = base_query\n",
        "\n",
        "        self.logger.info(\"Querying for new pages to process...\")\n",
        "        try:\n",
        "            # Use fetch_record_batch for memory-efficient iteration\n",
        "            for batch in self.con.execute(final_query).fetch_record_batch(batch_size):\n",
        "                yield batch.to_pandas()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Could not query Parquet files. Please check the input path: {e}\")\n",
        "            return\n",
        "\n",
        "class TextExtractor:\n",
        "    \"\"\"Extracts clean text from raw HTML.\"\"\"\n",
        "    def extract(self, html_content: str) -> str:\n",
        "        if not html_content or not isinstance(html_content, str):\n",
        "            return \"\"\n",
        "        text = trafilatura.extract(html_content, include_comments=False, include_tables=False, deduplicate=True)\n",
        "        if text:\n",
        "            text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
        "            return text.strip()\n",
        "        return \"\"\n",
        "\n",
        "class EmbeddingGenerator:\n",
        "    \"\"\"Generates embeddings for a list of texts.\"\"\"\n",
        "    def __init__(self, model_name: str, logger: ILogger):\n",
        "        self.logger = logger\n",
        "        self.logger.info(f\"Loading embedding model: {model_name}...\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.logger.info(\"Model loaded successfully.\")\n",
        "\n",
        "    def generate(self, texts: list[str]) -> np.ndarray:\n",
        "        self.logger.info(f\"Generating embeddings for {len(texts)} texts...\")\n",
        "        return self.model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "class DataSaver:\n",
        "    \"\"\"Saves a batch of embeddings to a Parquet file.\"\"\"\n",
        "    def __init__(self, output_path: str, logger: ILogger):\n",
        "        self.output_path = output_path\n",
        "        self.logger = logger\n",
        "\n",
        "    def save_batch(self, df_batch: pd.DataFrame, batch_num: int):\n",
        "        \"\"\"Saves a DataFrame of URLs and embeddings to a uniquely named file.\"\"\"\n",
        "        batch_filename = f\"embeddings_batch_{int(time.time())}_{batch_num}.parquet\"\n",
        "        batch_output_path = os.path.join(self.output_path, batch_filename)\n",
        "        df_batch.to_parquet(batch_output_path, index=False)\n",
        "        self.logger.info(f\"✅ Saved batch {batch_num} to {batch_filename}\")\n",
        "\n",
        "#\n",
        "# --- Step 5: The Main Pipeline Orchestrator ---\n",
        "#\n",
        "\n",
        "class EmbeddingPipeline:\n",
        "    \"\"\"Orchestrates the entire embedding generation process.\"\"\"\n",
        "    def __init__(self, config: EmbeddingConfig, logger: ILogger, state_manager: EmbeddingStateManager,\n",
        "                 data_loader: DataLoader, text_extractor: TextExtractor,\n",
        "                 embedding_generator: EmbeddingGenerator, data_saver: DataSaver):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.state_manager = state_manager\n",
        "        self.data_loader = data_loader\n",
        "        self.text_extractor = text_extractor\n",
        "        self.embedding_generator = embedding_generator\n",
        "        self.data_saver = data_saver\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"A generator that executes the pipeline and yields status updates.\"\"\"\n",
        "        try:\n",
        "            yield \"Initializing...\"\n",
        "            processed_urls = self.state_manager.get_processed_urls()\n",
        "\n",
        "            yield \"Loading model and querying data...\"\n",
        "            data_stream = self.data_loader.stream_unprocessed_data(processed_urls, self.config.batch_size)\n",
        "\n",
        "            batch_num = 1\n",
        "            processed_in_this_session = False\n",
        "            for df_batch in data_stream:\n",
        "                processed_in_this_session = True\n",
        "                status_msg = f\"Processing Batch {batch_num} ({len(df_batch)} pages)...\"\n",
        "                self.logger.info(status_msg)\n",
        "                yield status_msg\n",
        "\n",
        "                # Extract Text\n",
        "                df_batch['clean_text'] = [self.text_extractor.extract(html) for html in tqdm(df_batch['Content'], desc=\"Extracting Text\")]\n",
        "                df_batch = df_batch[df_batch['clean_text'].str.len() > 100]\n",
        "\n",
        "                if df_batch.empty:\n",
        "                    self.logger.info(\"Batch had no pages with sufficient text after cleaning.\")\n",
        "                    continue\n",
        "\n",
        "                # Generate Embeddings\n",
        "                embeddings = self.embedding_generator.generate(df_batch['clean_text'].tolist())\n",
        "\n",
        "                # Save Batch\n",
        "                output_df = pd.DataFrame({'URL': df_batch['URL'], 'Embedding': [e.tolist() for e in embeddings]})\n",
        "                self.data_saver.save_batch(output_df, batch_num)\n",
        "                batch_num += 1\n",
        "\n",
        "            if not processed_in_this_session:\n",
        "                self.logger.info(\"No new pages to process. The dataset is already up to date.\")\n",
        "                yield \"Already up to date.\"\n",
        "            else:\n",
        "                self.logger.info(\"All new batches processed successfully.\")\n",
        "                yield \"Finished\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.exception(f\"A critical pipeline error occurred: {e}\")\n",
        "            yield f\"Error: {e}\"\n",
        "\n",
        "\n",
        "#\n",
        "# --- Step 6: Gradio UI and Main Execution Logic ---\n",
        "#\n",
        "\n",
        "def run_gradio_interface(input_path: str, output_path: str, batch_size: int):\n",
        "    \"\"\"Wires up all components and runs the pipeline, yielding UI updates.\"\"\"\n",
        "    log_stream = io.StringIO()\n",
        "    logger = ConsoleAndGradioLogger(log_stream)\n",
        "\n",
        "    config = EmbeddingConfig(input_path=input_path, output_path=output_path, batch_size=batch_size)\n",
        "\n",
        "    # Instantiate all our components\n",
        "    state_manager = EmbeddingStateManager(config.output_path, logger)\n",
        "    data_loader = DataLoader(config.input_path, logger)\n",
        "    text_extractor = TextExtractor()\n",
        "    embedding_generator = EmbeddingGenerator(config.model_name, logger)\n",
        "    data_saver = DataSaver(config.output_path, logger)\n",
        "\n",
        "    pipeline = EmbeddingPipeline(config, logger, state_manager, data_loader, text_extractor, embedding_generator, data_saver)\n",
        "\n",
        "    final_status = \"Initializing...\"\n",
        "    for status in pipeline.run():\n",
        "        final_status = status\n",
        "        # Yield the current status and the full log content\n",
        "        yield status, log_stream.getvalue(), \"\"\n",
        "\n",
        "    # Generate final summary after the pipeline finishes\n",
        "    try:\n",
        "        output_glob_path = os.path.join(output_path, '*.parquet')\n",
        "        total_embeddings = duckdb.query(f\"SELECT COUNT(URL) FROM read_parquet('{output_glob_path}')\").fetchone()[0]\n",
        "        summary_md = f\"### ✅ Pipeline Finished\\n\\n- **Final Status:** {final_status}\\n- **Total embeddings saved:** {total_embeddings}\\n- **Output location:** `{output_path}`\"\n",
        "    except Exception as e:\n",
        "        summary_md = f\"### Pipeline Finished\\n\\n- Could not generate summary. Error: {e}\"\n",
        "\n",
        "    yield final_status, log_stream.getvalue(), summary_md\n",
        "\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 🤖 Resumable Embedding Pipeline\")\n",
        "    gr.Markdown(\"This tool reads HTML from Parquet files, cleans it, generates embeddings, and saves the results in batches. It can be stopped and resumed at any time.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"## 1. Configuration\")\n",
        "            input_path_box = gr.Textbox(\n",
        "                label=\"Input Parquet Folder Path\",\n",
        "                value=EmbeddingConfig.input_path\n",
        "            )\n",
        "            output_path_box = gr.Textbox(\n",
        "                label=\"Output Embeddings Directory Path\",\n",
        "                value=EmbeddingConfig.output_path\n",
        "            )\n",
        "            batch_size_slider = gr.Slider(\n",
        "                minimum=10, maximum=50, value=EmbeddingConfig.batch_size, step=10,\n",
        "                label=\"Batch Size\",\n",
        "                info=\"How many pages to process in memory at a time.\"\n",
        "            )\n",
        "            start_button = gr.Button(\"🚀 Start/Resume Embedding Generation\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"## 2. Status & Results\")\n",
        "            status_output = gr.Textbox(label=\"Current Status\", interactive=False)\n",
        "            log_output = gr.Textbox(label=\"Detailed Logs\", interactive=False, lines=10, max_lines=20)\n",
        "            summary_output = gr.Markdown(\"---\")\n",
        "\n",
        "    start_button.click(\n",
        "        fn=run_gradio_interface,\n",
        "        inputs=[input_path_box, output_path_box, batch_size_slider],\n",
        "        outputs=[status_output, log_output, summary_output]\n",
        "    )\n",
        "\n",
        "#\n",
        "# --- Launch the Application ---\n",
        "#\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive/', force_remount=True)\n",
        "        demo.launch(debug=True, share=True)\n",
        "    except Exception as e:\n",
        "        print(\"Could not launch Gradio demo in this environment.\")\n",
        "        print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}