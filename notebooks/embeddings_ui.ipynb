{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xw4QDh41TRn"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlhbx_4z1WEx"
   },
   "source": [
    "# pip install -r requirements.txt first, before continuing with the rest of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikTkalDc07HY"
   },
   "outputs": [],
   "source": [
    "# Installing necessary packages!\n",
    "# These should ideally be in requirements.txt and installed once for the environment.\n",
    "# But for a notebook that's meant to be self-contained for easy sharing/running,\n",
    "# it's common to keep them here.\n",
    "# !pip install trafilatura sentence-transformers torch pandas pyarrow duckdb scipy -q\n",
    "# !pip install fireducks\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress a common warning from the sentence-transformers library\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\"\n",
    ")\n",
    "\n",
    "# Add the project root to the Python path so we can import from src\n",
    "# Adjust this path if your notebook is located differently relative to the 'src' folder\n",
    "# This assumes your project root is '/content/drive/My Drive/WebKnoGraph'\n",
    "project_root = \"/content/drive/My Drive/WebKnoGraph\"  # Explicitly set\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"sys.path: {sys.path}\")\n",
    "\n",
    "# Google Colab Drive Mount\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Check if already mounted before attempting to mount again\n",
    "    if not os.path.exists(\"/content/drive/My Drive\"):\n",
    "        drive.mount(\"/content/drive/\")\n",
    "        print(\"Google Drive mounted successfully.\")\n",
    "    else:\n",
    "        print(\"Google Drive already mounted.\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab environment. Skipping Google Drive mount.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error mounting Google Drive: {e}\")\n",
    "\n",
    "# Import from your refactored backend and shared modules\n",
    "import gradio as gr\n",
    "import io\n",
    "import duckdb\n",
    "\n",
    "# Specific imports for the Embedding Pipeline\n",
    "from src.backend.config.embeddings_config import EmbeddingConfig\n",
    "from src.backend.data.embedding_state_manager import EmbeddingStateManager\n",
    "from src.backend.data.embeddings_loader import DataLoader\n",
    "from src.backend.data.embeddings_saver import DataSaver\n",
    "from src.backend.utils.text_processing import TextExtractor\n",
    "from src.backend.utils.embedding_generation import EmbeddingGenerator\n",
    "from src.backend.services.embeddings_service import EmbeddingPipeline\n",
    "from src.shared.logging_config import (\n",
    "    ConsoleAndGradioLogger,\n",
    ")  # Using the updated generic logger\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs58VQei0_UG"
   },
   "outputs": [],
   "source": [
    "def run_gradio_interface(input_path: str, output_path: str, batch_size: int):\n",
    "    \"\"\"Wires up all components and runs the pipeline, yielding UI updates.\"\"\"\n",
    "    log_stream = io.StringIO()\n",
    "    logger = ConsoleAndGradioLogger(\n",
    "        log_stream, logger_name=\"EmbeddingLogger\"\n",
    "    )  # Pass logger_name\n",
    "\n",
    "    config = EmbeddingConfig(\n",
    "        input_path=input_path, output_path=output_path, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Instantiate all our components\n",
    "    state_manager = EmbeddingStateManager(config.output_path, logger)\n",
    "    data_loader = DataLoader(config.input_path, logger)\n",
    "    text_extractor = TextExtractor()\n",
    "    embedding_generator = EmbeddingGenerator(config.model_name, logger)\n",
    "    data_saver = DataSaver(config.output_path, logger)\n",
    "\n",
    "    pipeline = EmbeddingPipeline(\n",
    "        config,\n",
    "        logger,\n",
    "        state_manager,\n",
    "        data_loader,\n",
    "        text_extractor,\n",
    "        embedding_generator,\n",
    "        data_saver,\n",
    "    )\n",
    "\n",
    "    final_status = \"Initializing...\"\n",
    "    for status in pipeline.run():\n",
    "        final_status = status\n",
    "        # Yield the current status and the full log content\n",
    "        yield status, log_stream.getvalue(), \"\"\n",
    "\n",
    "    # Generate final summary after the pipeline finishes\n",
    "    try:\n",
    "        # Ensure output_glob_path uses forward slashes for DuckDB even on Windows\n",
    "        output_glob_path = os.path.join(output_path, \"*.parquet\").replace(os.sep, \"/\")\n",
    "        total_embeddings = duckdb.query(\n",
    "            f\"SELECT COUNT(URL) FROM read_parquet('{output_glob_path}')\"\n",
    "        ).fetchone()[0]\n",
    "        summary_md = f\"### âœ… Pipeline Finished\\n\\n- **Final Status:** {final_status}\\n- **Total embeddings saved:** {total_embeddings}\\n- **Output location:** `{output_path}`\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Could not generate final summary. Error: {e}\")\n",
    "        summary_md = (\n",
    "            f\"### Pipeline Finished\\n\\n- Could not generate summary. Error: {e}\"\n",
    "        )\n",
    "\n",
    "    yield final_status, log_stream.getvalue(), summary_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8hKopmM1Bif"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ðŸ¤– Resumable Embedding Pipeline\")\n",
    "    gr.Markdown(\n",
    "        \"This tool reads HTML from Parquet files, cleans it, generates embeddings, and saves the results in batches. It can be stopped and resumed at any time.\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"## 1. Configuration\")\n",
    "            input_path_box = gr.Textbox(\n",
    "                label=\"Input Parquet Folder Path\", value=EmbeddingConfig.input_path\n",
    "            )\n",
    "            output_path_box = gr.Textbox(\n",
    "                label=\"Output Embeddings Directory Path\",\n",
    "                value=EmbeddingConfig.output_path,\n",
    "            )\n",
    "            batch_size_slider = gr.Slider(\n",
    "                minimum=10,\n",
    "                maximum=50,\n",
    "                value=EmbeddingConfig.batch_size,\n",
    "                step=10,\n",
    "                label=\"Batch Size\",\n",
    "                info=\"How many pages to process in memory at a time.\",\n",
    "            )\n",
    "            start_button = gr.Button(\n",
    "                \"ðŸš€ Start/Resume Embedding Generation\", variant=\"primary\"\n",
    "            )\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"## 2. Status & Results\")\n",
    "            status_output = gr.Textbox(label=\"Current Status\", interactive=False)\n",
    "            log_output = gr.Textbox(\n",
    "                label=\"Detailed Logs\", interactive=False, lines=10, max_lines=20\n",
    "            )\n",
    "            summary_output = gr.Markdown(\"---\")\n",
    "\n",
    "    start_button.click(\n",
    "        fn=run_gradio_interface,\n",
    "        inputs=[input_path_box, output_path_box, batch_size_slider],\n",
    "        outputs=[status_output, log_output, summary_output],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9QFhe671C-H"
   },
   "outputs": [],
   "source": [
    "# --- Launch the Application ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "\n",
    "        # It's better to mount once at the very start of the notebook\n",
    "        # or main.py. If it's already mounted, no need to force_remount unless necessary.\n",
    "        # Check if already mounted before attempting to mount again (as in embeddings_ui.ipynb Cell 1)\n",
    "        if not os.path.exists(\"/content/drive/My Drive\"):\n",
    "            drive.mount(\"/content/drive/\")\n",
    "            print(\"Google Drive mounted successfully.\")\n",
    "        else:\n",
    "            print(\"Google Drive already mounted.\")\n",
    "\n",
    "        demo.launch(debug=True, share=True)\n",
    "    except Exception as e:\n",
    "        print(\"Could not launch Gradio demo in this environment.\")\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}